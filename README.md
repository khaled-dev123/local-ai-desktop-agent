# local-ai-desktop-agent
# ğŸ–¥ï¸ Ollama + UI-TARS Desktop Agent (macOS)

<p align="center">
  <b>Run a powerful Desktop AI Agent fully locally on macOS</b><br>
  <i>No Cloud â€¢ No OpenAI â€¢ Full Privacy</i>
</p>

---

## ğŸš€ Overview

This repository documents how to run **UI-TARS Desktop** (by ByteDance) locally on **macOS**
using **Ollama** as the LLM backend.

Instead of using the OpenAI API, UI-TARS is connected to a **local Ollama model**
via an OpenAI-compatible endpoint.

> âš ï¸ This project focuses on **installation, configuration, and macOS security setup**.  
> UI-TARS itself is developed and maintained by ByteDance.

---

## ğŸ§  Model & Runtime

| Component | Value |
|--------|------|
| LLM Runtime | Ollama |
| Model | `qwen2.5-coder:7b` |
| Mode | Fully Local / Offline |
| OS | macOS |

---

## âœ¨ Key Features

- âœ… Fully local AI agent
- âœ… No cloud / no API cost
- âœ… Desktop UI automation
- âœ… OpenAI-compatible API via Ollama
- âœ… macOS security-aware setup
- âœ… Privacy-first execution

---

## ğŸ–¼ï¸ Demo

### ğŸ§© UI-TARS Desktop Interface
<p align="center">
  <img src="Ollama-ui-agent-macos/images/UI-interface.png" width="85%" alt="UI-TARS Interface">
</p>

### ğŸ–¥ï¸ Running from Terminal
<p align="center">
  <img src="Ollama-ui-agent-macos/images/Terminal.png" width="85%" alt="UI-TARS Terminal">
</p>

---

## ğŸ“¦ Requirements

- macOS
- Ollama (official installer)
  - https://ollama.com
- UI-TARS Desktop
  - https://github.com/bytedance/UI-TARS-desktop

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Install Ollama

Download and install Ollama from the official website:

```bash
https://ollama.com
```
Pull the model:

ollama pull qwen2.5-coder:7b


Start Ollama:
```
ollama serve
```

Ollama API will be available at:

http://localhost:11434

2ï¸âƒ£ Install UI-TARS Desktop

Clone the official repository:
```
git clone https://github.com/bytedance/UI-TARS-desktop.git
cd UI-TARS-desktop
```

Follow the official instructions in their README to complete installation.

3ï¸âƒ£ Connect UI-TARS to Ollama (Important)

UI-TARS expects an OpenAI-style API by default.
Use the command below to redirect it to local Ollama:
```
agent-tars \
  --provider openai \
  --baseUrl http://localhost:11434/v1 \
  --model qwen2.5-coder:7b \
  --apiKey ollama
```

ğŸ” Notes:

provider openai â†’ required by UI-TARS

baseUrl â†’ local Ollama endpoint

apiKey â†’ dummy value (required but not used)

## ğŸ macOS Security Configuration

macOS blocks **GUI automation** by default.  
To allow UI-TARS to control the desktop, specific permissions **must be granted manually**.

### ğŸ“„ Configuration File
This repository includes:

```text
config/macos-security.yaml
```
âš™ï¸ Required Permissions

Open:

System Settings â†’ Privacy & Security

Then enable the following:

ğŸ§© Accessibility

ğŸ¥ Screen Recording

ğŸ¤– Automation

ğŸ“‚ Full Disk Access (optional, but recommended)

â— Without these permissions, UI-TARS cannot interact with the desktop UI.

###ğŸ“ Repository Structure

```
Ollama-ui-agent-macos/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ macos-security.yaml
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ UI-interface.png
â”‚   â””â”€â”€ Terminal.png
â””â”€â”€ README.md
```
ğŸ” Privacy & Offline Mode

ğŸš« No OpenAI API calls

â˜ï¸ No cloud dependency

ğŸ”’ All inference runs locally

ğŸ§  Full control over the model and data

<p align="center"> <b>Privacy-first. Offline-ready. Fully local AI.</b> ğŸš€ </p> 
